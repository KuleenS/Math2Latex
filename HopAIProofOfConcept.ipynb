{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "#add more parameters\n",
    "#add a confusion matrix\n",
    "#mess around with hyperparameters\n",
    "#related research - increasing kernel size \n",
    "#grid search/ray tune \n",
    "\n",
    "#data augementation \n",
    "#mnist \n",
    "#noise \n",
    "#-30 to 30 degree rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing data\n",
    "transform = transforms.Compose([\n",
    "transforms.ToTensor(), #turns JPG to Tensor Object\n",
    "transforms.Grayscale(num_output_channels=1), #turns the 3 layers RGB to 1 layer black and white,\n",
    "transforms.Normalize(mean=[0.5,], std=[0.5,]) #some nornmalization of the grayscale,\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataset object of the file system\n",
    "data = torchvision.datasets.ImageFolder(root='./archive/data/extracted_images/', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the splits for the dataset\n",
    "#taking 75% as train and 25% as hold out for test\n",
    "trainsize = int(len(data)*0.75)\n",
    "testsize = len(data)-trainsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting randomly our dataset into our chunks\n",
    "train_set, test_set = torch.utils.data.random_split(data, (trainsize,testsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dataloader object (basically an iterator through our dataset that batches our files together) \n",
    "train_data_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True,  num_workers=1)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=True,  num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining our ConvNet\n",
    "class Net(nn.Module):   \n",
    "  def __init__(self):\n",
    "      super(Net, self).__init__()\n",
    "\n",
    "      self.cnn_layers = nn.Sequential(\n",
    "          # Defining a 2D convolution layer\n",
    "          nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n",
    "          nn.BatchNorm2d(4),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "          # Defining another 2D convolution layer\n",
    "          nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "          nn.BatchNorm2d(4),\n",
    "          nn.ReLU(inplace=True),\n",
    "          nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "      )\n",
    "\n",
    "      self.linear_layers = nn.Sequential(\n",
    "          nn.Linear(484, 82)\n",
    "      )\n",
    "\n",
    "  # Defining the forward pass    \n",
    "  def forward(self, x):\n",
    "      x = self.cnn_layers(x)\n",
    "      x = x.view(x.size(0), -1)\n",
    "      x = self.linear_layers(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=484, out_features=82, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "# defining the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# defining the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    #put our loss and model on GPU\n",
    "    #this makes it faster as GPUs have lots of multiprocessing capabilities and deal well with Matrix Multiplication and vectors \n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VivekKuleen\\anaconda3\\envs\\reg\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.28676804357694\n",
      "Epoch 1 - Training loss: 0.7981486507537984\n",
      "85.92047775760327\n",
      "Epoch 2 - Training loss: 0.5117747645560505\n",
      "88.21812585111212\n",
      "Epoch 3 - Training loss: 0.41919635673473354\n",
      "89.12739729913754\n",
      "Epoch 4 - Training loss: 0.38262471149616784\n",
      "89.6859396277803\n",
      "Epoch 5 - Training loss: 0.3624864388671562\n",
      "90.0015603722197\n",
      "Epoch 6 - Training loss: 0.3476395557230382\n",
      "90.39200805719474\n",
      "Epoch 7 - Training loss: 0.3354759863493233\n",
      "90.53315081706764\n",
      "Epoch 8 - Training loss: 0.32908969350517236\n",
      "90.69308896958694\n",
      "Epoch 9 - Training loss: 0.3211075116116537\n",
      "90.85444564230595\n",
      "Epoch 10 - Training loss: 0.31619349061044316\n"
     ]
    }
   ],
   "source": [
    "#train for 10 epochs\n",
    "for i in range(10):\n",
    "    #creating loss per epoch and correct in training set \n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    #loop through our dataloader\n",
    "    for images, labels in train_data_loader:\n",
    "        #put data on GPU\n",
    "        if torch.cuda.is_available():\n",
    "          images = images.cuda()\n",
    "          labels = labels.cuda()\n",
    "\n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward pass through our model\n",
    "        output = model(images)\n",
    "        #get the predicitions for that batch\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        #calculate the loss \n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        #This is where the model learns by backpropagating\n",
    "        loss.backward()\n",
    "        \n",
    "        #And optimizes its weights here\n",
    "        optimizer.step()\n",
    "        #keep track of our loss and sum\n",
    "        running_loss += loss.item()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * (correct / (len(train_data_loader)*32))\n",
    "    print(accuracy)\n",
    "    print(\"Epoch {} - Training loss: {}\".format(i+1, running_loss/len(train_data_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Images Tested = 93994\n",
      "\n",
      "Model Accuracy = 0.8275528225205864\n"
     ]
    }
   ],
   "source": [
    "#test loop\n",
    "#pretty much the same thing as the dev but we do not back prop the error\n",
    "correct_count, all_count = 0, 0\n",
    "for images,labels in test_data_loader:\n",
    "  for i in range(len(labels)):\n",
    "    if torch.cuda.is_available():\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "    img = images[i].view(1, 1, 45, 45)\n",
    "    with torch.no_grad():\n",
    "        logps = model(img)\n",
    "\n",
    "    \n",
    "    ps = torch.exp(logps)\n",
    "    probab = list(ps.cpu()[0])\n",
    "    pred_label = probab.index(max(probab))\n",
    "    true_label = labels.cpu()[i]\n",
    "    if(true_label == pred_label):\n",
    "      correct_count += 1\n",
    "    all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fa706d29148685102f4d2caf4b4a1631bca60a8faf710f50a41d3fdd530c8e64"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('reg': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
